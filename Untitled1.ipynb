{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f723edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from Scripts.models import FacePrediction\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cd73bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'predict' #'train' or 'predict'\n",
    "model_type = 'vgg16'\n",
    "model_tag = 'base'\n",
    "model_id = '{:s}_{:s}'.format(model_type, model_tag)\n",
    "model_dir = './saved_model/model_{:s}.h5'.format(model_id)\n",
    "bs = 8\n",
    "epochs = 2\n",
    "freeze_backbone = True # True => transfer learning; False => train from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9a040f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FacePrediction(img_dir = './data/face_aligned/', model_type = model_type)\n",
    "model.define_model(freeze_backbone = freeze_backbone)\n",
    "model.load_weights(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80865c40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 741ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[17.67527]], dtype=float32),\n",
       " array([[51.30267]], dtype=float32),\n",
       " array([[0.6158781]], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('./data/test/test_aligned/albert-einstein.jpg',  show_img = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58fc710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.utils.layer_utils import get_source_inputs\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def crop_img(im,x,y,w,h):\n",
    "    return im[y:(y+h),x:(x+w),:]\n",
    "\n",
    "def detect_face(face_path):\n",
    "    img = cv2.cvtColor(cv2.imread(face_path), cv2.COLOR_BGR2RGB)\n",
    "    box = detector.detect_faces(img)[0]\n",
    "    return box\n",
    "\n",
    "def detect_faces(face_path):\n",
    "    #img = cv2.cvtColor(cv2.imread(face_path), cv2.COLOR_BGR2RGB)\n",
    "    img = load_img(face_path)\n",
    "    img = img_to_array(img)\n",
    "    box = detector.detect_faces(img)\n",
    "    return box\n",
    "\n",
    "def draw_box(face_path = './test/trump.jpg', plot = True):\n",
    "    \n",
    "    boxes = detect_faces(face_path)\n",
    "    im = np.array(Image.open(face_path), dtype=np.uint8)\n",
    "    \n",
    "    if plot:\n",
    "        # Create figure and axes\n",
    "        num_box = len(boxes)\n",
    "        fig,ax = plt.subplots(1, (1 + num_box))\n",
    "        fig.set_size_inches(4 * (1 + num_box),4)\n",
    "        # Display the image\n",
    "        ax[0].imshow(im)\n",
    "        ax[0].axis('off')\n",
    "        # Create a Rectangle patch\n",
    "        for idx, box in enumerate(boxes):\n",
    "            box_x, box_y, box_w, box_h = box['box']\n",
    "            rect = patches.Rectangle((box_x, box_y), box_w, box_h, linewidth=1,edgecolor='r',facecolor='none')\n",
    "            ax[0].add_patch(rect)\n",
    "            ax[0].text(box_x, box_y, '{:3.2f}'.format(box['confidence']))\n",
    "            for i in box['keypoints'].keys():\n",
    "                circle = patches.Circle(box['keypoints'][i], radius = 5, color = 'red')\n",
    "                ax[0].add_patch(circle)\n",
    "            ax[1 + idx].imshow(crop_img(im, *box['box']))\n",
    "            ax[1 + idx].axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    res = [crop_img(im, *box['box']) for box in boxes]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c30a617e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A69F7E1CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 844ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A69F7E1CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "11/11 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n"
     ]
    }
   ],
   "source": [
    "detector = MTCNN()\n",
    "box = detect_face('data/test/single_face/Kim Jong-un.jpg')\n",
    "im = plt.imread('data/test/single_face/Kim Jong-un.jpg')\n",
    "cropped = crop_img(im, *box['box'])\n",
    "plt.imsave('data/test/new/Kim Jong-un.jpg', crop_img(im, *box['box']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce7360b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[128, 127, 133],\n",
       "        [125, 124, 130],\n",
       "        [128, 127, 133],\n",
       "        ...,\n",
       "        [ 16,  16,  18],\n",
       "        [ 13,  13,  15],\n",
       "        [ 16,  16,  18]],\n",
       "\n",
       "       [[134, 133, 139],\n",
       "        [131, 130, 136],\n",
       "        [135, 134, 140],\n",
       "        ...,\n",
       "        [ 12,  12,  14],\n",
       "        [ 12,  12,  14],\n",
       "        [ 15,  15,  17]],\n",
       "\n",
       "       [[136, 135, 141],\n",
       "        [136, 135, 141],\n",
       "        [143, 142, 148],\n",
       "        ...,\n",
       "        [ 10,  10,  12],\n",
       "        [ 14,  14,  16],\n",
       "        [ 15,  15,  17]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 34,  34,  34],\n",
       "        [ 33,  33,  33],\n",
       "        [ 33,  33,  33],\n",
       "        ...,\n",
       "        [ 17,  17,  19],\n",
       "        [ 21,  21,  23],\n",
       "        [ 22,  22,  24]],\n",
       "\n",
       "       [[ 32,  32,  32],\n",
       "        [ 30,  30,  32],\n",
       "        [ 31,  31,  33],\n",
       "        ...,\n",
       "        [ 20,  20,  22],\n",
       "        [ 15,  15,  17],\n",
       "        [ 19,  19,  21]],\n",
       "\n",
       "       [[ 31,  31,  33],\n",
       "        [ 31,  30,  35],\n",
       "        [ 32,  31,  36],\n",
       "        ...,\n",
       "        [ 21,  21,  23],\n",
       "        [ 15,  15,  17],\n",
       "        [ 17,  17,  19]]], dtype=uint8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94c3e180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[46.430965]], dtype=float32),\n",
       " array([[29.433643]], dtype=float32),\n",
       " array([[0.02577626]], dtype=float32)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('data/test/new/Kim Jong-un.jpg', show_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa3dca2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_1 (Conv2D)               (None, 224, 224, 64  1792        ['input_12[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_2 (Conv2D)               (None, 224, 224, 64  36928       ['conv1_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 112, 112, 64  0           ['conv1_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_1 (Conv2D)               (None, 112, 112, 12  73856       ['pool1[0][0]']                  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2_2 (Conv2D)               (None, 112, 112, 12  147584      ['conv2_1[0][0]']                \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " pool2 (MaxPooling2D)           (None, 56, 56, 128)  0           ['conv2_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv3_1 (Conv2D)               (None, 56, 56, 256)  295168      ['pool2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv3_2 (Conv2D)               (None, 56, 56, 256)  590080      ['conv3_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv3_3 (Conv2D)               (None, 56, 56, 256)  590080      ['conv3_2[0][0]']                \n",
      "                                                                                                  \n",
      " pool3 (MaxPooling2D)           (None, 28, 28, 256)  0           ['conv3_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv4_1 (Conv2D)               (None, 28, 28, 512)  1180160     ['pool3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv4_2 (Conv2D)               (None, 28, 28, 512)  2359808     ['conv4_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv4_3 (Conv2D)               (None, 28, 28, 512)  2359808     ['conv4_2[0][0]']                \n",
      "                                                                                                  \n",
      " pool4 (MaxPooling2D)           (None, 14, 14, 512)  0           ['conv4_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv5_1 (Conv2D)               (None, 14, 14, 512)  2359808     ['pool4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv5_2 (Conv2D)               (None, 14, 14, 512)  2359808     ['conv5_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv5_3 (Conv2D)               (None, 14, 14, 512)  2359808     ['conv5_2[0][0]']                \n",
      "                                                                                                  \n",
      " pool5 (MaxPooling2D)           (None, 7, 7, 512)    0           ['conv5_3[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)            (None, 25088)        0           ['pool5[0][0]']                  \n",
      "                                                                                                  \n",
      " bmi_fc1 (Dense)                (None, 128)          3211392     ['flatten_7[0][0]']              \n",
      "                                                                                                  \n",
      " age_fc1 (Dense)                (None, 128)          3211392     ['flatten_7[0][0]']              \n",
      "                                                                                                  \n",
      " sex_fc1 (Dense)                (None, 128)          3211392     ['flatten_7[0][0]']              \n",
      "                                                                                                  \n",
      " bmi_bn1 (BatchNormalization)   (None, 128)          512         ['bmi_fc1[0][0]']                \n",
      "                                                                                                  \n",
      " age_bn1 (BatchNormalization)   (None, 128)          512         ['age_fc1[0][0]']                \n",
      "                                                                                                  \n",
      " sex_bn1 (BatchNormalization)   (None, 128)          512         ['sex_fc1[0][0]']                \n",
      "                                                                                                  \n",
      " bmi_act1 (Activation)          (None, 128)          0           ['bmi_bn1[0][0]']                \n",
      "                                                                                                  \n",
      " age_act1 (Activation)          (None, 128)          0           ['age_bn1[0][0]']                \n",
      "                                                                                                  \n",
      " sex_act1 (Activation)          (None, 128)          0           ['sex_bn1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 128)          0           ['bmi_act1[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['age_act1[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 128)          0           ['sex_act1[0][0]']               \n",
      "                                                                                                  \n",
      " bmi_fc2 (Dense)                (None, 128)          16512       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " age_fc2 (Dense)                (None, 128)          16512       ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " sex_fc2 (Dense)                (None, 128)          16512       ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " bmi_bn2 (BatchNormalization)   (None, 128)          512         ['bmi_fc2[0][0]']                \n",
      "                                                                                                  \n",
      " age_bn2 (BatchNormalization)   (None, 128)          512         ['age_fc2[0][0]']                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " sex_bn2 (BatchNormalization)   (None, 128)          512         ['sex_fc2[0][0]']                \n",
      "                                                                                                  \n",
      " bmi_act2 (Activation)          (None, 128)          0           ['bmi_bn2[0][0]']                \n",
      "                                                                                                  \n",
      " age_act2 (Activation)          (None, 128)          0           ['age_bn2[0][0]']                \n",
      "                                                                                                  \n",
      " sex_act2 (Activation)          (None, 128)          0           ['sex_bn2[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 128)          0           ['bmi_act2[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 128)          0           ['age_act2[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 128)          0           ['sex_act2[0][0]']               \n",
      "                                                                                                  \n",
      " bmi (Dense)                    (None, 1)            129         ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " age (Dense)                    (None, 1)            129         ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " sex (Dense)                    (None, 1)            129         ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24,401,859\n",
      "Trainable params: 9,685,635\n",
      "Non-trainable params: 14,716,224\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model_type = 'vgg16'\n",
    "model_tag = 'base'\n",
    "model_id = '{:s}_{:s}'.format(model_type, model_tag)\n",
    "model_dir = './saved_model/model_{:s}.h5'.format(model_id)\n",
    "modl = tf.keras.models.load_model(model_dir)\n",
    "modl.load_w\n",
    "#model = load_weights(model_dir)\n",
    "#preds = modl.predict('./data/test/test_aligned/albert-einstein.jpg',  show_img = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f0fccbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.utils.layer_utils import get_source_inputs\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def crop_img(im,x,y,w,h):\n",
    "    return im[y:(y+h),x:(x+w),:]\n",
    "\n",
    "def detect_face(face_path):\n",
    "    img = cv2.cvtColor(cv2.imread(face_path), cv2.COLOR_BGR2RGB)\n",
    "    box = detector.detect_faces(img)[0]\n",
    "    return box\n",
    "\n",
    "def detect_faces(face_path):\n",
    "    #img = cv2.cvtColor(cv2.imread(face_path), cv2.COLOR_BGR2RGB)\n",
    "    img = load_img(face_path)\n",
    "    img = img_to_array(img)\n",
    "    box = detector.detect_faces(img)\n",
    "    return box\n",
    "\n",
    "def draw_box(face_path = './test/trump.jpg', plot = False):\n",
    "    \n",
    "    boxes = detect_faces(face_path)\n",
    "    im = np.array(Image.open(face_path), dtype=np.uint8)\n",
    "    \n",
    "    if plot:\n",
    "        # Create figure and axes\n",
    "        num_box = len(boxes)\n",
    "        fig,ax = plt.subplots(1, (1 + num_box))\n",
    "        fig.set_size_inches(4 * (1 + num_box),4)\n",
    "        # Display the image\n",
    "        ax[0].imshow(im)\n",
    "        ax[0].axis('off')\n",
    "        # Create a Rectangle patch\n",
    "        for idx, box in enumerate(boxes):\n",
    "            box_x, box_y, box_w, box_h = box['box']\n",
    "            rect = patches.Rectangle((box_x, box_y), box_w, box_h, linewidth=1,edgecolor='r',facecolor='none')\n",
    "            ax[0].add_patch(rect)\n",
    "            ax[0].text(box_x, box_y, '{:3.2f}'.format(box['confidence']))\n",
    "            for i in box['keypoints'].keys():\n",
    "                circle = patches.Circle(box['keypoints'][i], radius = 5, color = 'red')\n",
    "                ax[0].add_patch(circle)\n",
    "            ax[1 + idx].imshow(crop_img(im, *box['box']))\n",
    "            ax[1 + idx].axis('off')\n",
    "        #plt.show()\n",
    "    \n",
    "    res = [crop_img(im, *box['box']) for box in boxes]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fcde0332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [89]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m box \u001b[38;5;241m=\u001b[39m detect_face(test_dir\u001b[38;5;241m+\u001b[39mimg)\n\u001b[0;32m     19\u001b[0m im \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mimread(test_dir\u001b[38;5;241m+\u001b[39mimg)\n\u001b[1;32m---> 20\u001b[0m cropped \u001b[38;5;241m=\u001b[39m crop_img(im, \u001b[38;5;241m*\u001b[39m\u001b[43mbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbox\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     21\u001b[0m plt\u001b[38;5;241m.\u001b[39mimsave(test_processed_dir\u001b[38;5;241m+\u001b[39mimg, crop_img(im, \u001b[38;5;241m*\u001b[39mbox[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbox\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import shutil\n",
    "def cut_negative_boundary(box):\n",
    "    res = []\n",
    "    for x in box['box']:\n",
    "        if x < 0:\n",
    "            x = 0\n",
    "        res.append(x)\n",
    "    box['box'] = res\n",
    "    return box\n",
    "\n",
    "test_processed_dir = 'data/test/new/'\n",
    "test_dir = 'data/test/tst/'\n",
    "if os.path.exists(test_processed_dir):\n",
    "    shutil.rmtree(test_processed_dir)\n",
    "os.mkdir(test_processed_dir)\n",
    "for img in tqdm(os.listdir(test_dir)):\n",
    "    box = detect_face(test_dir+img)\n",
    "    im = plt.imread(test_dir+img)\n",
    "    cropped = crop_img(im, *box['box'])\n",
    "    plt.imsave(test_processed_dir+img, crop_img(im, *box['box']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc021675",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict('./data/test/test_aligned/albert-einstein.jpg', show_img = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dab2196d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "2/2 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 450ms/step\n",
      "[{'box': [355, 75, 266, 347], 'confidence': 0.9983004927635193, 'keypoints': {'left_eye': (432, 209), 'right_eye': (551, 208), 'nose': (492, 276), 'mouth_left': (445, 346), 'mouth_right': (544, 347)}}]\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'box': [355, 75, 266, 347],\n",
       " 'confidence': 0.9983004927635193,\n",
       " 'keypoints': {'left_eye': (432, 209),\n",
       "  'right_eye': (551, 208),\n",
       "  'nose': (492, 276),\n",
       "  'mouth_left': (445, 346),\n",
       "  'mouth_right': (544, 347)}}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.cvtColor(cv2.imread('./data/test/single_face/' + 'trump.jpg'), cv2.COLOR_BGR2RGB)\n",
    "detector = MTCNN()\n",
    "print(detector.detect_faces(img))\n",
    "box = detector.detect_faces(img)[0]\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "70115aec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ 77,  62,  31],\n",
       "         [ 84,  69,  38],\n",
       "         [ 87,  72,  41],\n",
       "         ...,\n",
       "         [123, 103,  76],\n",
       "         [131, 111,  84],\n",
       "         [135, 115,  88]],\n",
       "\n",
       "        [[ 76,  60,  34],\n",
       "         [ 84,  68,  43],\n",
       "         [ 84,  68,  42],\n",
       "         ...,\n",
       "         [139, 119,  92],\n",
       "         [135, 115,  88],\n",
       "         [137, 117,  90]],\n",
       "\n",
       "        [[ 66,  50,  25],\n",
       "         [ 73,  57,  34],\n",
       "         [ 77,  61,  36],\n",
       "         ...,\n",
       "         [138, 118,  91],\n",
       "         [142, 122,  95],\n",
       "         [136, 116,  89]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 10,  23,  32],\n",
       "         [ 10,  23,  32],\n",
       "         [  9,  22,  31],\n",
       "         ...,\n",
       "         [  9,  21,  33],\n",
       "         [  9,  21,  33],\n",
       "         [  8,  20,  32]],\n",
       "\n",
       "        [[  9,  22,  31],\n",
       "         [  8,  18,  28],\n",
       "         [  6,  20,  29],\n",
       "         ...,\n",
       "         [  7,  19,  31],\n",
       "         [ 11,  23,  35],\n",
       "         [  9,  21,  33]],\n",
       "\n",
       "        [[ 11,  24,  33],\n",
       "         [ 11,  21,  31],\n",
       "         [  8,  22,  31],\n",
       "         ...,\n",
       "         [  8,  20,  32],\n",
       "         [ 10,  22,  34],\n",
       "         [ 10,  22,  34]]]], dtype=uint8)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = draw_box('./data/test/single_face/' + 'trump.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9fb3a8b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 277455 into shape (224,224,224,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [118]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 277455 into shape (224,224,224,3)"
     ]
    }
   ],
   "source": [
    "np.array(res).reshape(224, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9145e077",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_10\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 349, 265, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [116]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileuii7vafu.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_10\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 349, 265, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "modl.predict(np.array(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15975bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './saved_model/model_vgg16_base.h5'\n",
    "#model = FacePrediction(img_dir = './data/face_aligned/285929.jpg', model_type = 'predict')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e90f2744",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_weights\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./saved_model/model_vgg16_base.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_weights' is not defined"
     ]
    }
   ],
   "source": [
    "model = load_weights('./saved_model/model_vgg16_base.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b390aec",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/face_aligned/285929.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:910\u001b[0m, in \u001b[0;36mTensorShape.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    909\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v2_behavior:\n\u001b[1;32m--> 910\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dims\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    911\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims[key]\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "m = model.predict('./data/face_aligned/285929.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d93a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# program to capture single image from webcam in python\n",
    "\n",
    "# importing OpenCV library\n",
    "import cv2 as cv\n",
    "\n",
    "# initialize the camera\n",
    "# If you have multiple camera connected with\n",
    "# current device, assign a value in cam_port\n",
    "# variable according to that\n",
    "cam_port = 0\n",
    "cam = cv.VideoCapture(cam_port)\n",
    "\n",
    "# reading the input using the camera\n",
    "result, image = cam.read()\n",
    "\n",
    "# If image will detected without any error,\n",
    "# show result\n",
    "if result:\n",
    "    cv.namedWindow(\"cam-test\")\n",
    "    cv.imshow(\"cam-test\",image)\n",
    "    #cv.waitKey(0)\n",
    "    cv.destroyWindow(\"cam-test\")\n",
    "    cv.imwrite(\"passport.jpg\",image)\n",
    "    cam.release() \n",
    "    # showing result, it take frame name and image\n",
    "    # output\n",
    "    cv.imshow(\"passport\", image)\n",
    "\n",
    "    # saving image in local storage\n",
    "    cv.imwrite(\"passport.jpg\", image)\n",
    "\n",
    "    # If keyboard interrupt occurs, destroy image\n",
    "    # window\n",
    "    #cv.waitKey(0)\n",
    "    cv.destroyWindow(\"passport\")\n",
    "\n",
    "    # If captured image is corrupted, moving to else part\n",
    "else:\n",
    "    print(\"No image detected. Please! try again\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8be9395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d49f53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 539 entries, 0 to 538\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Id          539 non-null    int64 \n",
      " 1   age         539 non-null    int64 \n",
      " 2   gender      539 non-null    int64 \n",
      " 3   height(cm)  539 non-null    int64 \n",
      " 4   image       539 non-null    object\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 21.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/training.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df3c679e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id            0.921885\n",
       "age          -0.036857\n",
       "gender        0.166788\n",
       "height(cm)    1.000000\n",
       "Name: height(cm), dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['height(cm)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69aef18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['height(Meters)'] = df['height(cm)'] * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48184f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Id', 'height(cm)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15e94cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(539, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc5e1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['age', 'gender']]\n",
    "y = df['height(Meters)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b16410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf261bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a1d1e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "670b800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd8fc5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "regModel = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30c1a454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31d11aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00057561  0.06383162]\n"
     ]
    }
   ],
   "source": [
    "print(regModel.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1da56bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24fa51a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd45a2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d4ed0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>1.764061</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1.825591</td>\n",
       "      <td>1.56</td>\n",
       "      <td>-0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1.761759</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1.768666</td>\n",
       "      <td>1.62</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>1.761183</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1.762335</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1.768666</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.759457</td>\n",
       "      <td>1.71</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>1.772120</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>1.769242</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     predictions  actual  difference\n",
       "486     1.764061    1.90        0.14\n",
       "73      1.825591    1.56       -0.27\n",
       "349     1.761759    1.80        0.04\n",
       "86      1.768666    1.62       -0.15\n",
       "457     1.761183    1.87        0.11\n",
       "..           ...     ...         ...\n",
       "297     1.762335    1.78        0.02\n",
       "296     1.768666    1.78        0.01\n",
       "158     1.759457    1.71       -0.05\n",
       "357     1.772120    1.80        0.03\n",
       "291     1.769242    1.78        0.01\n",
       "\n",
       "[135 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data={'predictions': predictions, 'actual': y_test, 'difference': y_test - np.round(predictions, 2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61ca33a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8df34043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1e42d7e4be0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b0969a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot((y_test-predictions),bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "333aadd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be68d34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01681674526205068\n"
     ]
    }
   ],
   "source": [
    "print(metrics.r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb8d5411",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.09143736346934986\n",
      "MSE: 0.014413331647070857\n",
      "RMSE: 0.12005553567858025\n"
     ]
    }
   ],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24449c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
